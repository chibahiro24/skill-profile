# ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é€æ˜æ€§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

**æœ€çµ‚æ›´æ–°**: 2026-02-13  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0

---

## ğŸ“œ æ¦‚è¦

Skill Profileã¯ã€**ã™ã¹ã¦ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å…¬é–‹ã™ã‚‹**ã“ã¨ã§ã€ä»–ã®ã‚­ãƒ£ãƒªã‚¢ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¨ä¸€ç·šã‚’ç”»ã—ã¾ã™ã€‚ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã•ã‚Œã‚‹ã™ã¹ã¦ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©³ç´°ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### ãªãœã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å…¬é–‹ã™ã‚‹ã®ã‹ï¼Ÿ

1. **ä¿¡é ¼æ€§ã®ç¢ºä¿**: ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãªæ¨å¥¨ã§ã¯ãªãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç†è§£ãƒ»æ¤œè¨¼ã§ãã‚‹
2. **å…¬å¹³æ€§ã®ä¿è¨¼**: ãƒã‚¤ã‚¢ã‚¹ã‚’æ¤œå‡ºã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§æ”¹å–„ã§ãã‚‹
3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ãƒ‘ãƒ¯ãƒ¼ãƒ¡ãƒ³ãƒˆ**: è‡ªåˆ†ã®ã‚­ãƒ£ãƒªã‚¢ã‚’è‡ªåˆ†ã§æ±ºã‚ã‚‹åŠ›ã‚’æä¾›
4. **ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä¿ƒé€²**: ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚ˆã‚‹æ”¹å–„

---

## ğŸ¯ 1. é¡ä¼¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 1.1 ç›®çš„

ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãƒ»çµŒé¨“ãŒé¡ä¼¼ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ç™ºè¦‹ã—ã€å½¼ã‚‰ã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’å‚è€ƒã«ã™ã‚‹ã€‚

### 1.2 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°

#### **ãƒ™ã‚¯ãƒˆãƒ«è¡¨ç¾**

å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’å¤šæ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ç¾ï¼š

```python
def create_user_vector(user_profile):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    
    æ¬¡å…ƒ: 200æ¬¡å…ƒï¼ˆã‚¹ã‚­ãƒ«æ•°ã«å¿œã˜ã¦å‹•çš„ï¼‰
    - ã‚½ãƒ•ãƒˆã‚¹ã‚­ãƒ«: 50æ¬¡å…ƒ
    - ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—: 30æ¬¡å…ƒ
    - ãƒ“ã‚¸ãƒã‚¹ã‚¹ã‚­ãƒ«: 40æ¬¡å…ƒ
    - ã‚¢ãƒ³ãƒˆãƒ¬ãƒ—ãƒ¬ãƒŠãƒ¼ã‚·ãƒƒãƒ—: 20æ¬¡å…ƒ
    - çµŒå–¶ã‚¹ã‚­ãƒ«: 20æ¬¡å…ƒ
    - ãƒãƒ¼ãƒ‰ã‚¹ã‚­ãƒ«: 40æ¬¡å…ƒ
    """
    vector = []
    
    # ã‚½ãƒ•ãƒˆã‚¹ã‚­ãƒ«ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    soft_skills = [
        user_profile.communication,
        user_profile.time_management,
        user_profile.problem_solving,
        user_profile.teamwork,
        user_profile.self_management
    ]
    vector.extend(soft_skills)
    
    # å„ã‚¹ã‚­ãƒ«ã‚’0-100ã®ç¯„å›²ã§æ­£è¦åŒ–
    # ... (å…¨ã‚¹ã‚­ãƒ«ã‚«ãƒ†ã‚´ãƒªã«å¯¾ã—ã¦åŒæ§˜)
    
    return np.array(vector)
```

#### **é¡ä¼¼åº¦è¨ˆç®—**

ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ä½¿ç”¨ï¼š

```python
def calculate_similarity(user_a, user_b, weights=None):
    """
    2äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
    
    Args:
        user_a: ãƒ¦ãƒ¼ã‚¶ãƒ¼Aã®ãƒ™ã‚¯ãƒˆãƒ«
        user_b: ãƒ¦ãƒ¼ã‚¶ãƒ¼Bã®ãƒ™ã‚¯ãƒˆãƒ«
        weights: å„æ¬¡å…ƒã®é‡ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯None=å‡ç­‰ï¼‰
    
    Returns:
        similarity_score: 0-1ã®é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
    """
    if weights is None:
        weights = DEFAULT_WEIGHTS
    
    # é‡ã¿ä»˜ããƒ™ã‚¯ãƒˆãƒ«
    weighted_a = user_a * weights
    weighted_b = user_b * weights
    
    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
    similarity = cosine_similarity(weighted_a, weighted_b)
    
    return similarity

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé‡ã¿ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
DEFAULT_WEIGHTS = {
    'soft_skills': 0.40,        # ã‚½ãƒ•ãƒˆã‚¹ã‚­ãƒ«: 40%
    'leadership': 0.15,          # ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—: 15%
    'business_skills': 0.20,     # ãƒ“ã‚¸ãƒã‚¹ã‚¹ã‚­ãƒ«: 20%
    'entrepreneurship': 0.10,    # ã‚¢ãƒ³ãƒˆãƒ¬ãƒ—ãƒ¬ãƒŠãƒ¼ã‚·ãƒƒãƒ—: 10%
    'management': 0.05,          # çµŒå–¶ã‚¹ã‚­ãƒ«: 5%
    'hard_skills': 0.10          # ãƒãƒ¼ãƒ‰ã‚¹ã‚­ãƒ«: 10%
}
```

#### **ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**

é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã«åŠ ãˆã¦ã€ä»¥ä¸‹ã®æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼š

```python
def filter_similar_users(current_user, candidate_users):
    """
    é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    """
    filtered = []
    
    for candidate in candidate_users:
        # 1. çµŒé¨“å¹´æ•°ã®å·®ãŒÂ±3å¹´ä»¥å†…
        if abs(candidate.years_experience - current_user.years_experience) > 3:
            continue
        
        # 2. æ¥­ç•Œã®é–¢é€£æ€§
        if not has_related_industry(current_user.industry, candidate.industry):
            continue
        
        # 3. é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒ0.7ä»¥ä¸Š
        similarity = calculate_similarity(current_user, candidate)
        if similarity < 0.7:
            continue
        
        filtered.append({
            'user': candidate,
            'similarity': similarity,
            'explanation': generate_explanation(current_user, candidate, similarity)
        })
    
    # é¡ä¼¼åº¦é †ã«ã‚½ãƒ¼ãƒˆ
    filtered.sort(key=lambda x: x['similarity'], reverse=True)
    
    return filtered[:10]  # ä¸Šä½10äººã‚’è¿”ã™
```

### 1.3 æ¨å¥¨ç†ç”±ã®ç”Ÿæˆ

```python
def generate_explanation(user_a, user_b, similarity_score):
    """
    ãªãœé¡ä¼¼ã¨åˆ¤å®šã•ã‚ŒãŸã‹ã®èª¬æ˜ã‚’ç”Ÿæˆ
    """
    explanation = {
        'overall_similarity': similarity_score,
        'breakdown': {}
    }
    
    # SHAPå€¤ã‚’ä½¿ç”¨ã—ã¦å„è¦ç´ ã®å¯„ä¸åº¦ã‚’è¨ˆç®—
    shap_values = calculate_shap_values(user_a, user_b)
    
    # å¯„ä¸åº¦ã®é«˜ã„è¦ç´ ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—
    top_contributors = sorted(shap_values.items(), key=lambda x: x[1], reverse=True)[:5]
    
    for skill, contribution in top_contributors:
        explanation['breakdown'][skill] = {
            'your_score': user_a.get_skill(skill),
            'their_score': user_b.get_skill(skill),
            'contribution': contribution,
            'reason': f'{skill}ã®ã‚¹ã‚³ã‚¢ãŒè¿‘ã„ï¼ˆã‚ãªãŸ: {user_a.get_skill(skill)}, ç›¸æ‰‹: {user_b.get_skill(skill)}ï¼‰'
        }
    
    return explanation
```

### 1.4 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **å®Ÿè£…ã‚³ãƒ¼ãƒ‰**: [`src/algorithms/similarity.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/algorithms/similarity.py)
- **ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰**: [`tests/algorithms/test_similarity.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/tests/algorithms/test_similarity.py)
- **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š**: [`config/similarity_config.yaml`](https://github.com/YOUR_ORG/skill-profile/blob/main/config/similarity_config.yaml)

---

## ğŸ›¤ï¸ 2. ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹æ¨å¥¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 2.1 ç›®çš„

é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¾¿ã£ãŸã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’åˆ†æã—ã€å®Ÿç¾å¯èƒ½ãªã‚­ãƒ£ãƒªã‚¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æç¤ºã™ã‚‹ã€‚

### 2.2 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°

#### **ã‚­ãƒ£ãƒªã‚¢ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰**

```python
import networkx as nx

def build_career_graph(similar_users):
    """
    é¡ä¼¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰
    
    ãƒãƒ¼ãƒ‰: ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆå½¹è·ï¼‰
    ã‚¨ãƒƒã‚¸: ãƒã‚¸ã‚·ãƒ§ãƒ³é–“ã®é·ç§»ï¼ˆé‡ã¿=é·ç§»å›æ•°ï¼‰
    """
    G = nx.DiGraph()
    
    for user in similar_users:
        career_history = user.get_career_history()
        
        for i in range(len(career_history) - 1):
            current_position = career_history[i]['position']
            next_position = career_history[i + 1]['position']
            transition_duration = career_history[i + 1]['start_date'] - career_history[i]['start_date']
            
            # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆã¾ãŸã¯é‡ã¿ã‚’å¢—ã‚„ã™ï¼‰
            if G.has_edge(current_position, next_position):
                G[current_position][next_position]['weight'] += 1
                G[current_position][next_position]['durations'].append(transition_duration)
            else:
                G.add_edge(current_position, next_position, weight=1, durations=[transition_duration])
    
    return G
```

#### **æ¨å¥¨ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã®æŠ½å‡º**

```python
def recommend_career_paths(current_position, career_graph, top_n=5):
    """
    ç¾åœ¨ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‹ã‚‰åˆ°é”å¯èƒ½ãªã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ã‚’æ¨å¥¨
    """
    paths = []
    
    # æ·±ã•å„ªå…ˆæ¢ç´¢ã§å¯èƒ½ãªãƒ‘ã‚¹ã‚’æ¢ç´¢ï¼ˆæœ€å¤§æ·±ã•3ï¼‰
    for target_node in career_graph.nodes():
        if target_node == current_position:
            continue
        
        # æœ€çŸ­ãƒ‘ã‚¹ã‚’è¤‡æ•°æ¢ç´¢
        all_paths = list(nx.all_simple_paths(career_graph, current_position, target_node, cutoff=3))
        
        for path in all_paths:
            # ãƒ‘ã‚¹ã®å®Ÿç¾å¯èƒ½æ€§ã‚’è¨ˆç®—
            feasibility = calculate_path_feasibility(path, career_graph)
            
            # æœŸå¾…åˆ°é”æœŸé–“ã‚’è¨ˆç®—
            expected_duration = calculate_expected_duration(path, career_graph)
            
            paths.append({
                'path': path,
                'target': target_node,
                'feasibility': feasibility,
                'expected_duration_years': expected_duration,
                'supporting_users': get_users_who_took_path(path, career_graph),
                'explanation': generate_path_explanation(path, career_graph)
            })
    
    # å®Ÿç¾å¯èƒ½æ€§é †ã«ã‚½ãƒ¼ãƒˆ
    paths.sort(key=lambda x: x['feasibility'], reverse=True)
    
    return paths[:top_n]

def calculate_path_feasibility(path, career_graph):
    """
    ãƒ‘ã‚¹ã®å®Ÿç¾å¯èƒ½æ€§ã‚’è¨ˆç®—
    
    å®Ÿç¾å¯èƒ½æ€§ = (é·ç§»ã®ç™ºç”Ÿé »åº¦ + ã‚¹ã‚­ãƒ«ãƒãƒƒãƒåº¦) / 2
    """
    transition_probabilities = []
    
    for i in range(len(path) - 1):
        current = path[i]
        next_pos = path[i + 1]
        
        # ã“ã®é·ç§»ã‚’è¡Œã£ãŸäººæ•°
        weight = career_graph[current][next_pos]['weight']
        
        # currentãƒã‚¸ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å…¨é·ç§»æ•°
        total_transitions = sum([career_graph[current][neighbor]['weight'] 
                                 for neighbor in career_graph.neighbors(current)])
        
        # é·ç§»ç¢ºç‡
        transition_prob = weight / total_transitions
        transition_probabilities.append(transition_prob)
    
    # å¹³å‡é·ç§»ç¢ºç‡
    avg_transition_prob = np.mean(transition_probabilities)
    
    return avg_transition_prob
```

### 2.3 æ¨å¥¨ç†ç”±ã®ç”Ÿæˆ

```python
def generate_path_explanation(path, career_graph):
    """
    ãªãœã“ã®ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹ãŒæ¨å¥¨ã•ã‚Œã‚‹ã®ã‹ã‚’èª¬æ˜
    """
    explanation = {
        'path': ' â†’ '.join(path),
        'reasons': []
    }
    
    for i in range(len(path) - 1):
        current = path[i]
        next_pos = path[i + 1]
        
        weight = career_graph[current][next_pos]['weight']
        durations = career_graph[current][next_pos]['durations']
        avg_duration = np.mean(durations)
        
        explanation['reasons'].append({
            'transition': f'{current} â†’ {next_pos}',
            'num_users': weight,
            'avg_duration_years': avg_duration.total_seconds() / (365 * 24 * 3600),
            'description': f'{weight}äººãŒ{current}ã‹ã‚‰{next_pos}ã«{avg_duration:.1f}å¹´ã§é·ç§»ã—ã¾ã—ãŸ'
        })
    
    return explanation
```

### 2.4 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **å®Ÿè£…ã‚³ãƒ¼ãƒ‰**: [`src/algorithms/career_path.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/algorithms/career_path.py)
- **ã‚°ãƒ©ãƒ•æ§‹ç¯‰**: [`src/algorithms/career_graph.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/algorithms/career_graph.py)
- **å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«**: [`src/visualization/career_path_viz.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/visualization/career_path_viz.py)

---

## ğŸ“Š 3. ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—åˆ†æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 3.1 ç›®çš„

ç›®æ¨™ãƒã‚¸ã‚·ãƒ§ãƒ³ã«å¿…è¦ãªã‚¹ã‚­ãƒ«ã¨ã€ç¾åœ¨ã®ã‚¹ã‚­ãƒ«ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’å®šé‡çš„ã«åˆ†æã™ã‚‹ã€‚

### 3.2 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°

```python
def analyze_skill_gap(current_skills, target_position):
    """
    ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’åˆ†æ
    """
    # ç›®æ¨™ãƒã‚¸ã‚·ãƒ§ãƒ³ã®å¹³å‡ã‚¹ã‚­ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    target_profile = get_average_profile_for_position(target_position)
    
    gaps = {}
    priorities = []
    
    for skill_name, target_score in target_profile.items():
        current_score = current_skills.get(skill_name, 0)
        gap = target_score - current_score
        
        if gap > 0:  # ä¸è¶³ã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ«
            # å„ªå…ˆåº¦ã‚’è¨ˆç®—
            priority = calculate_skill_priority(skill_name, gap, target_position)
            
            gaps[skill_name] = {
                'current': current_score,
                'target': target_score,
                'gap': gap,
                'priority': priority,
                'urgency': 'high' if gap > 20 else 'medium' if gap > 10 else 'low'
            }
            
            priorities.append((skill_name, priority))
    
    # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
    priorities.sort(key=lambda x: x[1], reverse=True)
    
    return {
        'gaps': gaps,
        'priorities': priorities,
        'overall_readiness': calculate_overall_readiness(current_skills, target_profile)
    }

def calculate_skill_priority(skill_name, gap, target_position):
    """
    ã‚¹ã‚­ãƒ«ç¿’å¾—ã®å„ªå…ˆåº¦ã‚’è¨ˆç®—
    
    å„ªå…ˆåº¦ = (ã‚®ãƒ£ãƒƒãƒ—ã®å¤§ãã• Ã— ã‚¹ã‚­ãƒ«ã®é‡è¦åº¦) / ç¿’å¾—é›£æ˜“åº¦
    """
    # ãã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ã‚¹ã‚­ãƒ«ã®é‡è¦åº¦ï¼ˆ0-1ï¼‰
    importance = get_skill_importance_for_position(skill_name, target_position)
    
    # ã‚¹ã‚­ãƒ«ã®ç¿’å¾—é›£æ˜“åº¦ï¼ˆ1-10ï¼‰
    difficulty = get_skill_learning_difficulty(skill_name)
    
    priority = (gap * importance) / difficulty
    
    return priority
```

### 3.3 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **å®Ÿè£…ã‚³ãƒ¼ãƒ‰**: [`src/algorithms/skill_gap.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/algorithms/skill_gap.py)

---

## ğŸ“ 4. å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹æ¨å¥¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 4.1 ç›®çš„

ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã®æœ€é©ãªå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¬›åº§ã€æ›¸ç±ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç­‰ï¼‰ã‚’æ¨å¥¨ã™ã‚‹ã€‚

### 4.2 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è©³ç´°

```python
def recommend_learning_resources(skill_gaps, user_preferences):
    """
    å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¨å¥¨
    """
    recommendations = []
    
    for skill_name, gap_info in skill_gaps['gaps'].items():
        # ãã®ã‚¹ã‚­ãƒ«ã«é–¢é€£ã™ã‚‹å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ã‚’æ¤œç´¢
        candidate_resources = search_learning_resources(skill_name)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ãƒ»çŠ¶æ³ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_resources = filter_by_preferences(
            candidate_resources, 
            user_preferences,
            gap_info['gap']
        )
        
        # åŠ¹æœã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        ranked_resources = rank_by_effectiveness(
            filtered_resources,
            skill_name,
            gap_info['current'],
            gap_info['target']
        )
        
        recommendations.append({
            'skill': skill_name,
            'priority': gap_info['priority'],
            'resources': ranked_resources[:3],  # ä¸Šä½3ã¤
            'expected_improvement': estimate_skill_improvement(ranked_resources[0], gap_info['gap'])
        })
    
    return recommendations

def rank_by_effectiveness(resources, skill_name, current_level, target_level):
    """
    å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ã‚’åŠ¹æœã®é«˜ã„é †ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    """
    scored_resources = []
    
    for resource in resources:
        # å®Ÿç¸¾ãƒ™ãƒ¼ã‚¹ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        effectiveness_score = calculate_effectiveness_score(resource, skill_name)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ™ãƒ«ã¨ã®é©åˆåº¦
        level_match = calculate_level_match(resource, current_level, target_level)
        
        # ç·åˆã‚¹ã‚³ã‚¢
        total_score = effectiveness_score * 0.7 + level_match * 0.3
        
        scored_resources.append({
            'resource': resource,
            'score': total_score,
            'explanation': generate_recommendation_explanation(resource, effectiveness_score, level_match)
        })
    
    scored_resources.sort(key=lambda x: x['score'], reverse=True)
    
    return scored_resources

def calculate_effectiveness_score(resource, skill_name):
    """
    å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹æœã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
    
    å®Ÿéš›ã«ã“ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½¿ã£ãŸäººãŒã€
    ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢ã‚’ã©ã‚Œã ã‘å‘ä¸Šã•ã›ãŸã‹ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã
    """
    # ã“ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚­ãƒ«å¤‰åŒ–ã‚’å–å¾—
    users_who_used = get_users_who_completed_resource(resource.id)
    
    improvements = []
    for user in users_who_used:
        before_score = user.get_skill_score_before(resource.completed_date, skill_name)
        after_score = user.get_skill_score_after(resource.completed_date, skill_name)
        improvement = after_score - before_score
        improvements.append(improvement)
    
    # å¹³å‡æ”¹å–„åº¦
    avg_improvement = np.mean(improvements) if improvements else 0
    
    # 0-1ã«æ­£è¦åŒ–
    effectiveness = min(avg_improvement / 20, 1.0)
    
    return effectiveness
```

### 4.3 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **å®Ÿè£…ã‚³ãƒ¼ãƒ‰**: [`src/algorithms/learning_recommendation.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/algorithms/learning_recommendation.py)

---

## âš–ï¸ 5. ãƒã‚¤ã‚¢ã‚¹æ¤œå‡ºãƒ»è£œæ­£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

### 5.1 ç›®çš„

æ¨å¥¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒæ€§åˆ¥ã€å¹´é½¢ã€åœ°åŸŸç­‰ã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å±æ€§ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã£ã¦ã„ãªã„ã‹ã‚’æ¤œå‡ºã—ã€è£œæ­£ã™ã‚‹ã€‚

### 5.2 ä½¿ç”¨ãƒ„ãƒ¼ãƒ«

- **Fairlearn**: MicrosoftãŒé–‹ç™ºã—ãŸãƒ•ã‚§ã‚¢ãƒã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **Aequitas**: ãƒã‚¤ã‚¢ã‚¹ç›£æŸ»ãƒ„ãƒ¼ãƒ«

### 5.3 ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º

```python
from fairlearn.metrics import MetricFrame, demographic_parity_difference
import pandas as pd

def detect_bias(predictions, sensitive_attributes):
    """
    æ¨å¥¨çµæœã®ãƒã‚¤ã‚¢ã‚¹ã‚’æ¤œå‡º
    """
    # æ¨å¥¨ã‚¹ã‚³ã‚¢ã¨å±æ€§ã‚’DataFrameã«
    df = pd.DataFrame({
        'recommendation_score': predictions,
        'gender': sensitive_attributes['gender'],
        'age_group': sensitive_attributes['age_group'],
        'ethnicity': sensitive_attributes['ethnicity']
    })
    
    # å„ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å±æ€§ã”ã¨ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æ¸¬å®š
    bias_report = {}
    
    # æ€§åˆ¥ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹
    gender_bias = demographic_parity_difference(
        y_true=[1] * len(predictions),  # å…¨å“¡ã«æ¨å¥¨ã™ã¹ã
        y_pred=(predictions > 0.5).astype(int),
        sensitive_features=df['gender']
    )
    bias_report['gender'] = gender_bias
    
    # å¹´é½¢ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹
    age_bias = demographic_parity_difference(
        y_true=[1] * len(predictions),
        y_pred=(predictions > 0.5).astype(int),
        sensitive_features=df['age_group']
    )
    bias_report['age'] = age_bias
    
    # ãƒã‚¤ã‚¢ã‚¹ã®è©³ç´°åˆ†æ
    metric_frame = MetricFrame(
        metrics={'selection_rate': selection_rate},
        y_true=[1] * len(predictions),
        y_pred=(predictions > 0.5).astype(int),
        sensitive_features=df[['gender', 'age_group']]
    )
    
    bias_report['detailed_analysis'] = metric_frame.by_group
    
    return bias_report

def selection_rate(y_true, y_pred):
    """é¸æŠç‡ã‚’è¨ˆç®—"""
    return np.mean(y_pred)
```

### 5.4 ãƒã‚¤ã‚¢ã‚¹è£œæ­£

```python
from fairlearn.reductions import ExponentiatedGradient, DemographicParity

def correct_bias(model, X_train, y_train, sensitive_features):
    """
    ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è£œæ­£
    """
    # Demographic Parityåˆ¶ç´„ã‚’é©ç”¨
    constraint = DemographicParity()
    
    # Exponentiated Gradientã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§å…¬å¹³ãªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    mitigator = ExponentiatedGradient(model, constraint)
    mitigator.fit(X_train, y_train, sensitive_features=sensitive_features)
    
    return mitigator
```

### 5.5 ãƒã‚¤ã‚¢ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã®å…¬é–‹

```python
def generate_bias_report(bias_detection_results):
    """
    ãƒã‚¤ã‚¢ã‚¹åˆ†æçµæœã‚’äººé–“ãŒèª­ã‚ã‚‹å½¢å¼ã§å‡ºåŠ›
    """
    report = {
        'analysis_date': datetime.now().isoformat(),
        'dataset_size': len(bias_detection_results),
        'findings': []
    }
    
    # æ€§åˆ¥ãƒã‚¤ã‚¢ã‚¹
    if abs(bias_detection_results['gender']) > 0.1:
        report['findings'].append({
            'type': 'gender_bias',
            'severity': 'high' if abs(bias_detection_results['gender']) > 0.2 else 'medium',
            'description': f'æ€§åˆ¥ã«ã‚ˆã‚‹æ¨å¥¨å·®ç•°ãŒ{bias_detection_results["gender"]:.2%}æ¤œå‡ºã•ã‚Œã¾ã—ãŸ',
            'corrective_action': 'è£œæ­£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã—ã€æ€§åˆ¥ã«ã‚ˆã‚‹å·®ç•°ã‚’0.05ä»¥ä¸‹ã«æŠ‘åˆ¶ã—ã¦ã„ã¾ã™'
        })
    
    # å¹´é½¢ãƒã‚¤ã‚¢ã‚¹
    if abs(bias_detection_results['age']) > 0.1:
        report['findings'].append({
            'type': 'age_bias',
            'severity': 'high' if abs(bias_detection_results['age']) > 0.2 else 'medium',
            'description': f'å¹´é½¢ã«ã‚ˆã‚‹æ¨å¥¨å·®ç•°ãŒ{bias_detection_results["age"]:.2%}æ¤œå‡ºã•ã‚Œã¾ã—ãŸ',
            'corrective_action': 'è£œæ­£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã—ã€å¹´é½¢ã«ã‚ˆã‚‹å·®ç•°ã‚’0.05ä»¥ä¸‹ã«æŠ‘åˆ¶ã—ã¦ã„ã¾ã™'
        })
    
    return report
```

### 5.6 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º**: [`src/fairness/bias_detection.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/fairness/bias_detection.py)
- **ãƒã‚¤ã‚¢ã‚¹è£œæ­£**: [`src/fairness/bias_mitigation.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/fairness/bias_mitigation.py)
- **ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ**: [`src/fairness/report_generator.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/fairness/report_generator.py)

---

## ğŸ“ˆ 6. èª¬æ˜å¯èƒ½AIï¼ˆXAIï¼‰ã®å®Ÿè£…

### 6.1 SHAPå€¤ã«ã‚ˆã‚‹èª¬æ˜

```python
import shap

def explain_recommendation(model, user_features):
    """
    SHAPã‚’ä½¿ç”¨ã—ã¦æ¨å¥¨ç†ç”±ã‚’èª¬æ˜
    """
    # SHAP Explainerã‚’åˆæœŸåŒ–
    explainer = shap.TreeExplainer(model)
    
    # SHAPå€¤ã‚’è¨ˆç®—
    shap_values = explainer.shap_values(user_features)
    
    # å„ç‰¹å¾´é‡ã®å¯„ä¸åº¦
    feature_contributions = {}
    for i, feature_name in enumerate(user_features.columns):
        contribution = shap_values[0][i]
        feature_contributions[feature_name] = {
            'value': user_features[feature_name].iloc[0],
            'contribution': contribution,
            'percentage': abs(contribution) / sum(abs(shap_values[0])) * 100
        }
    
    # å¯„ä¸åº¦ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_contributions = sorted(
        feature_contributions.items(),
        key=lambda x: abs(x[1]['contribution']),
        reverse=True
    )
    
    # äººé–“ãŒèª­ã‚ã‚‹èª¬æ˜æ–‡ã‚’ç”Ÿæˆ
    explanation = generate_human_readable_explanation(sorted_contributions[:5])
    
    return {
        'contributions': feature_contributions,
        'top_factors': sorted_contributions[:5],
        'explanation': explanation,
        'visualization': shap.force_plot(explainer.expected_value, shap_values[0], user_features)
    }

def generate_human_readable_explanation(top_factors):
    """
    SHAPå€¤ã‚’äººé–“ãŒèª­ã‚ã‚‹èª¬æ˜ã«å¤‰æ›
    """
    explanation = "ã“ã®æ¨å¥¨ã¯ä»¥ä¸‹ã®è¦å› ã«åŸºã¥ã„ã¦ã„ã¾ã™ï¼š\n\n"
    
    for i, (feature, data) in enumerate(top_factors, 1):
        percentage = data['percentage']
        value = data['value']
        contribution = data['contribution']
        
        if contribution > 0:
            direction = "ãƒã‚¸ãƒ†ã‚£ãƒ–"
        else:
            direction = "ãƒã‚¬ãƒ†ã‚£ãƒ–"
        
        explanation += f"{i}. **{feature}** (å¯„ä¸åº¦ {percentage:.1f}%)\n"
        explanation += f"   ç¾åœ¨ã®å€¤: {value}, å½±éŸ¿: {direction}\n"
        explanation += f"   èª¬æ˜: {generate_feature_explanation(feature, value, contribution)}\n\n"
    
    return explanation
```

### 6.2 ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å…¬é–‹å…ˆ

- **SHAPå®Ÿè£…**: [`src/explainability/shap_explainer.py`](https://github.com/YOUR_ORG/skill-profile/blob/main/src/explainability/shap_explainer.py)

---

## ğŸ”„ 7. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç›£æŸ»ãƒ»æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹

### 7.1 å®šæœŸç›£æŸ»

- **é »åº¦**: å››åŠæœŸã”ã¨
- **å®Ÿæ–½è€…**: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¡ãƒ³ãƒãƒ¼ + ã‚³ã‚¢ãƒãƒ¼ãƒ 

### 7.2 ç›£æŸ»é …ç›®

1. **ç²¾åº¦è©•ä¾¡**: æ¨å¥¨ã®çš„ä¸­ç‡
2. **ãƒã‚¤ã‚¢ã‚¹æ¤œå‡º**: ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å±æ€§ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹
3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: æ¨å¥¨ã®é©åˆ‡æ€§
4. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å®Ÿè¡Œé€Ÿåº¦

### 7.3 æ”¹å–„ãƒ•ãƒ­ãƒ¼

```mermaid
graph TB
    A[ç›£æŸ»å®Ÿæ–½] --> B[å•é¡Œç™ºè¦‹]
    B --> C[Issueä½œæˆ]
    C --> D[ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è­°è«–]
    D --> E[æ”¹å–„ææ¡ˆ]
    E --> F[ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼]
    F --> G[ãƒ†ã‚¹ãƒˆ]
    G --> H[æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤]
    H --> I[åŠ¹æœæ¸¬å®š]
    I --> A
```

### 7.4 å¤‰æ›´å±¥æ­´ã®å…¬é–‹

ã™ã¹ã¦ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å¤‰æ›´ã¯ã€ä»¥ä¸‹ã®æƒ…å ±ã¨å…±ã«å…¬é–‹ï¼š

- å¤‰æ›´æ—¥æ™‚
- å¤‰æ›´ç†ç”±
- å¤‰æ›´å†…å®¹ã®è©³ç´°
- æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ
- ãƒã‚¤ã‚¢ã‚¹åˆ†æçµæœ

---

## ğŸ“ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ»è³ªå•

ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹è³ªå•ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ä»¥ä¸‹ã§å—ã‘ä»˜ã‘ã¦ã„ã¾ã™ï¼š

- **GitHub Discussions**: [ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è³ªå•ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ](https://github.com/YOUR_ORG/skill-profile/discussions/categories/algorithms)
- **GitHub Issues**: [ãƒã‚°ãƒ»æ”¹å–„ææ¡ˆ](https://github.com/YOUR_ORG/skill-profile/issues/new?template=algorithm_feedback.md)
- **ãƒ¡ãƒ¼ãƒ«**: algorithms@skillprofile.example.com

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). "Why should i trust you?" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining.
- Lundberg, S. M., & Lee, S. I. (2017). A unified approach to interpreting model predictions. In Advances in neural information processing systems.
- Bird, S., et al. (2020). Fairlearn: A toolkit for assessing and improving fairness in AI. Microsoft Research.

---

**ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã¾ã™ã€‚æœ€æ–°ç‰ˆã¯å¸¸ã«GitHubã§ç¢ºèªã§ãã¾ã™ã€‚**
